{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScrapping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanyval/Bot/blob/main/WebScrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95z7Otogxjk5"
      },
      "source": [
        "import requests # La utilizaremos para solicitar una conexión al sitio web.\n",
        "from bs4 import BeautifulSoup as bs # Permitir manejar las etiquetas del sitio web.\n",
        "import re # Expresiones regulares\n",
        "import string # La usuaremos para los caracteres"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD5vUlKf0K9V",
        "outputId": "382a94ac-8620-4ce9-c67c-fcadcf18677d"
      },
      "source": [
        "URL = \"https://es.wikipedia.org/wiki/Web_scraping\"\n",
        "print(\"wikipedia.org\" in URL and URL.startswith(\"https://\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFVqZgEt0h7o"
      },
      "source": [
        "page = requests.get(URL)\n",
        "soup = bs(page.content, \"html.parser\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "vsU_JWri1XIB",
        "outputId": "cad1f600-36e2-4a23-d0e0-89faff180f47"
      },
      "source": [
        "parrafos = soup.find_all(\"p\")\n",
        "texto = []\n",
        "for parrafo in parrafos:\n",
        "  texto.append(parrafo.getText())\n",
        "\n",
        "text = \"\".join(str(texto))\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[\\'Web scraping o raspado web, es una técnica utilizada mediante programas de software para extraer información de sitios web.[1]\\\\u200b Usualmente, estos programas simulan la navegación de un humano en la World Wide Web ya sea utilizando el protocolo HTTP manualmente, o incrustando un navegador en una aplicación.\\\\n\\', \\'El web scraping está muy relacionado con la indexación de la web, la cual indexa la información de la web utilizando un robot y es una técnica universal adoptada por la mayoría de los motores de búsqueda. Sin embargo, el web scraping se enfoca más en la transformación de datos sin estructura en la web (como el formato HTML) en datos estructurados que pueden ser almacenados y analizados en una base de datos central, en una hoja de cálculo o en alguna otra fuente de almacenamiento. Alguno de los usos del web scraping son la comparación de precios en tiendas, la monitorización de datos relacionados con el clima de cierta región, la detección de cambios en sitios webs y la integración de datos en sitios webs. También es utilizado para obtener información relevante de un sitio a través de los rich snippets. \\\\n\\', \\'En los últimos años el web scraping se ha convertido en una técnica muy utilizada dentro del sector del posicionamiento web gracias a su capacidad de generar grandes cantidades de datos para crear contenidos de calidad.[2]\\\\u200b\\\\n\\', \\'Web scraping es el proceso de recopilar información de forma automática de la Web. Es un campo con desarrollos activos, compartiendo un propósito en común con la visión de la Web semántica. Utiliza soluciones prácticas basadas en tecnologías existentes que son comúnmente ad hoc. Existen distintos niveles de automatización que las existentes tecnologías de Web Scraping pueden brindar:\\\\n\\', \"El web scraping pudiera ir en contra de los términos de uso de algunos sitios webs. El cumplimiento de estos términos no está totalmente claro. Mientras que la duplicación de expresiones originales puede ser en muchos casos ilegal, en Estados Unidos la corte dictó en el caso Feist Publications v. Rural Telephone Service que la duplicación de hechos es permitida. Las cortes de Estados Unidos en ciertas ocasiones han reconocido que ciertos usos de los scrapers no deberían estar permitidos. Podría considerarse una computadora como una propiedad personal, y de esta forma el scraper estaría entrando sin autorización en esta propiedad. En el caso más conocido, eBay vs Bidder\\'s Edge, la segunda empresa tuvo que parar de realizar peticiones automáticas al sitio de eBay. En este caso, Bidder\\'s Edge pujaba automáticamente por ciertos productos en este sitio.\\\\n\", \\'Uno de las principales pruebas de scraping involucró a American Airlines y a una empresa llamada FareChase. American Airlines ganó esta batalla, haciendo que FareChase parara de vender un software que le permitía a los usuarios comparar tarifas en línea si el sitio de American Airlines era incluido. La aerolínea dijo que las búsquedas de FareChase entraban sin autorización en los servidores cuando recopilaban la información públicamente disponible.\\\\n\\', \\'Aunque las decisiones actualmente tomadas no son uniformes, es difícil ignorar que un patrón está emergiendo, en el cual podemos ver que las cortes están preparándose para proteger el contenido propietario en sitios webs comerciales, previendo de esta forma que este sea utilizado sin el consentimiento de los propietarios de los sitios. Sin embargo, el grado de protección de estos contenidos aún no está establecido, y dependerá del tipo de acceso realizado por los scrapers, de la cantidad de información recopilada y del grado en el que afecten estos factores al propietario del sitio web.\\\\n\\', \\'El administrador de un sitio web puede utilizar varias técnicas para detener o disminuir los pedidos de los scrapers. Algunas técnicas incluyen:\\\\n\\', \\'La mayoría de estos métodos suponen una merma importante en la usabilidad del sitio web en cuestión y los beneficios pueden ser muy puntuales.\\\\n\\', \\'Pese al planteamiento negativo de ciertos sectores, el rastreo automático y scraping son muy importantes para mantener la historia de Internet. Las iniciativas de archivado web se basan mayoritariamente en esta técnica.\\\\n\\']'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INZiEe_N2wOM"
      },
      "source": [
        "def clean_text(text : str):\n",
        "  text = re.sub(r\"\\\\n\", \"\", text)\n",
        "  texto = re.sub(r\"[%s]\" % re.escape(string.punctuation), \"\", text)\n",
        "  texto = re.sub(r\"([0-9]u[0-9]{3,}b)\", \"\", texto)\n",
        "  return texto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y13Man_83p0G",
        "outputId": "094ccbf6-bfa7-4a5c-8a91-49e0cef4b226"
      },
      "source": [
        "string.punctuation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "ASZXaZhz3EqH",
        "outputId": "0915a7f4-e256-40c7-bda1-f2a1f1c93d93"
      },
      "source": [
        "cleaned_text = clean_text(text)\n",
        "cleaned_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Web scraping o raspado web es una técnica utilizada mediante programas de software para extraer información de sitios web Usualmente estos programas simulan la navegación de un humano en la World Wide Web ya sea utilizando el protocolo HTTP manualmente o incrustando un navegador en una aplicación  El web scraping está muy relacionado con la indexación de la web la cual indexa la información de la web utilizando un robot y es una técnica universal adoptada por la mayoría de los motores de búsqueda Sin embargo el web scraping se enfoca más en la transformación de datos sin estructura en la web como el formato HTML en datos estructurados que pueden ser almacenados y analizados en una base de datos central en una hoja de cálculo o en alguna otra fuente de almacenamiento Alguno de los usos del web scraping son la comparación de precios en tiendas la monitorización de datos relacionados con el clima de cierta región la detección de cambios en sitios webs y la integración de datos en sitios webs También es utilizado para obtener información relevante de un sitio a través de los rich snippets   En los últimos años el web scraping se ha convertido en una técnica muy utilizada dentro del sector del posicionamiento web gracias a su capacidad de generar grandes cantidades de datos para crear contenidos de calidad  Web scraping es el proceso de recopilar información de forma automática de la Web Es un campo con desarrollos activos compartiendo un propósito en común con la visión de la Web semántica Utiliza soluciones prácticas basadas en tecnologías existentes que son comúnmente ad hoc Existen distintos niveles de automatización que las existentes tecnologías de Web Scraping pueden brindar  El web scraping pudiera ir en contra de los términos de uso de algunos sitios webs El cumplimiento de estos términos no está totalmente claro Mientras que la duplicación de expresiones originales puede ser en muchos casos ilegal en Estados Unidos la corte dictó en el caso Feist Publications v Rural Telephone Service que la duplicación de hechos es permitida Las cortes de Estados Unidos en ciertas ocasiones han reconocido que ciertos usos de los scrapers no deberían estar permitidos Podría considerarse una computadora como una propiedad personal y de esta forma el scraper estaría entrando sin autorización en esta propiedad En el caso más conocido eBay vs Bidders Edge la segunda empresa tuvo que parar de realizar peticiones automáticas al sitio de eBay En este caso Bidders Edge pujaba automáticamente por ciertos productos en este sitio  Uno de las principales pruebas de scraping involucró a American Airlines y a una empresa llamada FareChase American Airlines ganó esta batalla haciendo que FareChase parara de vender un software que le permitía a los usuarios comparar tarifas en línea si el sitio de American Airlines era incluido La aerolínea dijo que las búsquedas de FareChase entraban sin autorización en los servidores cuando recopilaban la información públicamente disponible  Aunque las decisiones actualmente tomadas no son uniformes es difícil ignorar que un patrón está emergiendo en el cual podemos ver que las cortes están preparándose para proteger el contenido propietario en sitios webs comerciales previendo de esta forma que este sea utilizado sin el consentimiento de los propietarios de los sitios Sin embargo el grado de protección de estos contenidos aún no está establecido y dependerá del tipo de acceso realizado por los scrapers de la cantidad de información recopilada y del grado en el que afecten estos factores al propietario del sitio web  El administrador de un sitio web puede utilizar varias técnicas para detener o disminuir los pedidos de los scrapers Algunas técnicas incluyen  La mayoría de estos métodos suponen una merma importante en la usabilidad del sitio web en cuestión y los beneficios pueden ser muy puntuales  Pese al planteamiento negativo de ciertos sectores el rastreo automático y scraping son muy importantes para mantener la historia de Internet Las iniciativas de archivado web se basan mayoritariamente en esta técnica '"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As-6MbahA_Bc"
      },
      "source": [
        "import codecs\n",
        "\n",
        "file = codecs.open(\"webscrapped_text.txt\", \"w\", \"utf-8\")\n",
        "file.write(cleaned_text)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXr2nF-NCw7H",
        "outputId": "c05684e6-b7ca-41fd-a768-8e35a7f487dd"
      },
      "source": [
        "palabra = \"almacenamiento\"\n",
        "letras = list(palabra)\n",
        "letras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'l', 'm', 'a', 'c', 'e', 'n', 'a', 'm', 'i', 'e', 'n', 't', 'o']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4av3sLrUC-Qz",
        "outputId": "dc6681e0-f18e-48e4-a3f4-24e640918f51"
      },
      "source": [
        "dic = {}\n",
        "for letra in letras:\n",
        "  siguientes = []\n",
        "  if letra not in dic.keys():\n",
        "    dic[letra] = 1\n",
        "  else:\n",
        "    dic[letra] += 1\n",
        "print(dic)\n",
        "freqa = 0\n",
        "for llave in dic.keys():\n",
        "  freq = dic[llave]/len(letras)\n",
        "  freqa += freq\n",
        "  dic[llave] = [freq, freqa]\n",
        "\n",
        "dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 3, 'l': 1, 'm': 2, 'c': 1, 'e': 2, 'n': 2, 'i': 1, 't': 1, 'o': 1}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': [0.21428571428571427, 0.21428571428571427],\n",
              " 'c': [0.07142857142857142, 0.5],\n",
              " 'e': [0.14285714285714285, 0.6428571428571428],\n",
              " 'i': [0.07142857142857142, 0.857142857142857],\n",
              " 'l': [0.07142857142857142, 0.2857142857142857],\n",
              " 'm': [0.14285714285714285, 0.42857142857142855],\n",
              " 'n': [0.14285714285714285, 0.7857142857142856],\n",
              " 'o': [0.07142857142857142, 0.9999999999999998],\n",
              " 't': [0.07142857142857142, 0.9285714285714284]}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}